{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15565edc-586a-4e2b-b6d0-492375d0c3a2",
   "metadata": {},
   "source": [
    "# An introduction to regression\n",
    "\n",
    "Lino Galiana  \n",
    "2025-10-07\n",
    "\n",
    "<div class=\"badge-container\"><div class=\"badge-text\">If you want to try the examples in this tutorial:</div><a href=\"https://github.com/linogaliana/python-datascientist-notebooks/blob/main/notebooks/en/modelisation/3_regression.ipynb\" target=\"_blank\" rel=\"noopener\"><img src=\"https://img.shields.io/static/v1?logo=github&label=&message=View%20on%20GitHub&color=181717\" alt=\"View on GitHub\"></a>\n",
    "<a href=\"https://datalab.sspcloud.fr/launcher/ide/vscode-python?autoLaunch=true&name=«3_regression»&init.personalInit=«https%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmain%2Fsspcloud%2Finit-vscode.sh»&init.personalInitArgs=«en/modelisation%203_regression%20correction»\" target=\"_blank\" rel=\"noopener\"><img src=\"https://custom-icon-badges.demolab.com/badge/SSP%20Cloud-Lancer_avec_VSCode-blue?logo=vsc&logoColor=white\" alt=\"Onyxia\"></a>\n",
    "<a href=\"https://datalab.sspcloud.fr/launcher/ide/jupyter-python?autoLaunch=true&name=«3_regression»&init.personalInit=«https%3A%2F%2Fraw.githubusercontent.com%2Flinogaliana%2Fpython-datascientist%2Fmain%2Fsspcloud%2Finit-jupyter.sh»&init.personalInitArgs=«en/modelisation%203_regression%20correction»\" target=\"_blank\" rel=\"noopener\"><img src=\"https://img.shields.io/badge/SSP%20Cloud-Lancer_avec_Jupyter-orange?logo=Jupyter&logoColor=orange\" alt=\"Onyxia\"></a>\n",
    "<a href=\"https://colab.research.google.com/github/linogaliana/python-datascientist-notebooks-colab//en/blob/main//notebooks/en/modelisation/3_regression.ipynb\" target=\"_blank\" rel=\"noopener\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a><br></div>\n",
    "\n",
    "The previous chapter aimed to propose a first model to understand the counties where the Republican Party wins. The variable of interest was bimodal (win or lose), placing us within the framework of a classification model.\n",
    "\n",
    "Now, using the same data, we will propose a regression model to explain the Republican Party’s score. The variable is thus continuous. We will ignore the fact that its bounds lie between 0 and 100, meaning that to be rigorous, we would need to transform the scale so that the data fits within this interval.\n",
    "\n",
    "Ce chapitre utilise toujours le même jeu de données, présenté dans l’[introduction\n",
    "de cette partie](index.qmd) : les données de vote aux élections présidentielles américaines\n",
    "croisées à des variables sociodémographiques.\n",
    "Le code\n",
    "est disponible [sur Github](https://github.com/linogaliana/python-datascientist/blob/main/content/modelisation/get_data.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfea38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade xlrd #colab bug verson xlrd\n",
    "!pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a23053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/linogaliana/python-datascientist/main/content/modelisation/get_data.py'\n",
    "r = requests.get(url, allow_redirects=True)\n",
    "open('getdata.py', 'wb').write(r.content)\n",
    "\n",
    "import getdata\n",
    "votes = getdata.create_votes_dataframes()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d011d36a-8fb2-416a-b561-8914a92b6f4c",
   "metadata": {},
   "source": [
    "This chapter will use several modeling *packages*, the main ones being `Scikit` and `Statsmodels`.\n",
    "Here is a suggested import for all these *packages*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8263bc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f54771e-a601-4569-bf92-5e97718307e5",
   "metadata": {},
   "source": [
    "# 1. General Principle\n",
    "\n",
    "The general principle of regression consists of finding a law $h_\\theta(X)$\n",
    "such that\n",
    "\n",
    "$$\n",
    "h_\\theta(X) = \\mathbb{E}_\\theta(Y|X)\n",
    "$$\n",
    "\n",
    "This formalization is extremely general and is not limited to linear regression.\n",
    "\n",
    "In econometrics, regression offers an alternative to maximum likelihood methods\n",
    "and moment methods. Regression encompasses a very broad range of methods, depending on the family of models\n",
    "(parametric, non-parametric, etc.) and model structures.\n",
    "\n",
    "## 1.1 Linear Regression\n",
    "\n",
    "This is the simplest way to represent the law $h_\\theta(X)$ as\n",
    "a linear combination of variables $X$ and parameters $\\theta$. In this case,\n",
    "\n",
    "$$\n",
    "\\mathbb{E}_\\theta(Y|X) = X\\beta\n",
    "$$\n",
    "\n",
    "This relationship is, under this formulation, theoretical. It must\n",
    "be estimated from the observed data $y$. The method of least squares aims to minimize\n",
    "the quadratic error between the prediction and the observed data (which explains\n",
    "why regression can be seen as a *Machine Learning* problem). In general, the method of\n",
    "least squares seeks to find the set of parameters $\\theta$ such that\n",
    "\n",
    "$$\n",
    "\\theta = \\arg \\min_{\\theta \\in \\Theta} \\mathbb{E}\\bigg[ \\left( y - h_\\theta(X) \\right)^2 \\bigg]\n",
    "$$\n",
    "\n",
    "Which, in the context of linear regression, is expressed as follows:\n",
    "\n",
    "$$\n",
    "\\beta = \\arg\\min \\mathbb{E}\\bigg[ \\left( y - X\\beta \\right)^2 \\bigg]\n",
    "$$\n",
    "\n",
    "When the theoretical model ($\\mathbb{E}_\\theta(Y|X) = X\\beta$) is applied to data,\n",
    "the model is formalized as follows:\n",
    "\n",
    "$$\n",
    "Y = X\\beta + \\epsilon\n",
    "$$\n",
    "\n",
    "With a certain distribution of the noise $\\epsilon$ that depends\n",
    "on the assumptions made. For example, with\n",
    "$\\epsilon \\sim \\mathcal{N}(0,\\sigma^2)$ i.i.d., the estimator $\\beta$ obtained\n",
    "is equivalent to the Maximum Likelihood Estimator, whose asymptotic theory\n",
    "ensures unbiasedness and minimum variance (Cramer-Rao bound).\n",
    "\n",
    "### 1.1.1 Application\n",
    "\n",
    "Under the guidance of the heirs of Siegfried (1913), our objective in this chapter is to explain and predict the Republican score based on some socioeconomic variables. Unlike the previous chapter, where we focused on a binary outcome (Republican victory/defeat), this time we will model the Republican score directly.\n",
    "\n",
    "The next exercise aims to demonstrate how to perform linear regression using `scikit`.\n",
    "In this area, `statsmodels` is significantly more comprehensive, as the following exercise will demonstrate.\n",
    "The main advantage of performing regressions with `scikit` is the ability to compare the results of linear regression with other regression models in the context of selecting the best predictive model.\n",
    "\n",
    "> **Exercise 1a: Linear Regression with scikit**\n",
    ">\n",
    "> 1.  Using a few variables, for example, *‘Unemployment_rate_2019’, ‘Median_Household_Income_2021’, ‘Percent of adults with less than a high school diploma, 2018-22’, “Percent of adults with a bachelor’s degree or higher, 2018-22”*, explain the variable `per_gop` using a training sample `X_train` prepared beforehand.\n",
    ">\n",
    "> ⚠️ Use the variable `Median_Household_Income_2021` in `log` form; otherwise, its scale might dominate and obscure other effects.\n",
    ">\n",
    "> 1.  Display the values of the coefficients, including the constant.\n",
    ">\n",
    "> 2.  Evaluate the relevance of the model using $R^2$ and assess the fit quality with the MSE.\n",
    ">\n",
    "> 3.  Plot a scatter plot of observed values and prediction errors. Do you observe any specification issues?\n",
    "\n",
    "In question 4, it can be observed that the distribution of errors is clearly not random with respect to $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722fb349-dd24-4ae5-9655-ca2e7a3bdcaf",
   "metadata": {},
   "source": [
    "The model therefore suffers from a specification issue, so work will need to be done on the selected variables later. Before that, we can redo this exercise using the `statsmodels` package.\n",
    "\n",
    "> **Exercise 1b: Linear Regression with statsmodels**\n",
    ">\n",
    "> This exercise aims to demonstrate how to perform linear regression using `statsmodels`, which offers features more similar to those of `R` and less oriented toward *Machine Learning*.\n",
    ">\n",
    "> The goal is still to explain the Republican score based on a few variables.\n",
    ">\n",
    "> 1.  Using a few variables, for example, *‘Unemployment_rate_2019’, ‘Median_Household_Income_2021’, ‘Percent of adults with less than a high school diploma, 2015-19’, “Percent of adults with a bachelor’s degree or higher, 2015-19”*, explain the variable `per_gop`.  \n",
    ">     ⚠️ Use the variable `Median_Household_Income_2021` in `log` form; otherwise, its scale might dominate and obscure other effects.\n",
    ">\n",
    "> 2.  Display a regression table.\n",
    ">\n",
    "> 3.  Evaluate the model’s relevance using the R^2.\n",
    ">\n",
    "> 4.  Use the `formula` API to regress the Republican score as a function of the variable `Unemployment_rate_2019`, `Unemployment_rate_2019` squared, and the log of `Median_Household_Income_2021`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f19966-ed95-4866-aab8-c0ab7c70cb35",
   "metadata": {},
   "source": [
    "> **Tip**\n",
    ">\n",
    "> To generate a well-formatted table for a report in $\\LaTeX$, you can use the method [`Summary.as_latex`](https://www.statsmodels.org/devel/generated/statsmodels.iolib.summary.Summary.as_latex.html#statsmodels.iolib.summary.Summary.as_latex). For an HTML report, you can use [`Summary.as_html`](https://www.statsmodels.org/devel/generated/statsmodels.iolib.summary.Summary.as_latex.html#statsmodels.iolib.summary.Summary.as_latex).\n",
    "\n",
    "> **Note**\n",
    ">\n",
    "> Users of `R` will find many familiar features in `statsmodels`, particularly the ability to use a formula to define a regression. The philosophy of `statsmodels` is similar to that which influenced the construction of `R`’s `stats` and `MASS` packages: providing a general-purpose library with a wide range of models.\n",
    ">\n",
    "> However, `statsmodels` benefits from being more modern compared to `R`’s packages. Since the 1990s, `R` packages aiming to provide missing features in `stats` and `MASS` have proliferated, while `statsmodels`, born in the 2010s, only had to propose a general framework (the *generalized estimating equations*) to encompass these models.\n",
    "\n",
    "## 1.2 La régression logistique\n",
    "\n",
    "We applied our linear regression to a continuous *outcome* variable.\n",
    "How do we handle a binary distribution?  \n",
    "In this case, $\\mathbb{E}_{\\theta} (Y|X) = \\mathbb{P}_{\\theta} (Y = 1|X)$.  \n",
    "Logistic regression can be seen as a linear probability model:\n",
    "\n",
    "$$\n",
    "\\text{logit}\\bigg(\\mathbb{E}_{\\theta}(Y|X)\\bigg) = \\text{logit}\\bigg(\\mathbb{P}_{\\theta}(Y = 1|X)\\bigg) = X\\beta\n",
    "$$\n",
    "\n",
    "The $\\text{logit}$ function is $]0,1[ \\to \\mathbb{R}: p \\mapsto \\log(\\frac{p}{1-p})$.\n",
    "\n",
    "It allows a probability to be transformed into $\\mathbb{R}$.\n",
    "Its reciprocal function is the sigmoid ($\\frac{1}{1 + e^{-x}}$),\n",
    "a central concept in *Deep Learning*.\n",
    "\n",
    "It should be noted that probabilities are not observed; what is observed is the binary\n",
    "*outcome* (0/1). This leads to two different perspectives on logistic regression:\n",
    "\n",
    "-   In econometrics, interest lies in the latent model that determines the choice of\n",
    "    the outcome. For example, if observing the choice to participate in the labor market,\n",
    "    the goal is to model the factors determining this choice;\n",
    "-   In *Machine Learning*, the latent model is only necessary to classify\n",
    "    observations into the correct category.\n",
    "\n",
    "Parameter estimation for $\\beta$ can be performed using maximum likelihood\n",
    "or regression, both of which are equivalent under certain assumptions.\n",
    "\n",
    "> **Exercise 2a: Logistic Regression with scikit**\n",
    ">\n",
    "> Using `scikit` with training and test samples:\n",
    ">\n",
    "> 1.  Evaluate the effect of the already-used variables on the probability of Republicans winning. Display the values of the coefficients.\n",
    "> 2.  Derive a confusion matrix and a measure of model quality.\n",
    "> 3.  Remove regularization using the `penalty` parameter. What effect does this have on the estimated parameters?\n",
    "\n",
    "> **Exercise 2b: Logistic Regression with statsmodels**\n",
    ">\n",
    "> Using training and test samples:\n",
    ">\n",
    "> 1.  Evaluate the effect of the already-used variables on the probability of Republicans winning.\n",
    "> 2.  Perform a likelihood ratio test regarding the inclusion of the (log)-income variable.\n",
    "\n",
    "The p-value of the likelihood ratio test being close to 1 means that the log-income variable almost certainly adds information to the model.\n",
    "\n",
    "> **Tip**\n",
    ">\n",
    "> The test statistic is:\n",
    "> $$\n",
    "> LR = -2\\log\\bigg(\\frac{\\mathcal{L}_{\\theta}}{\\mathcal{L}_{\\theta_0}}\\bigg) = -2(\\mathcal{l}_{\\theta} - \\mathcal{l}_{\\theta_0})\n",
    "> $$\n",
    "\n",
    "# 2. Going Further\n",
    "\n",
    "This chapter only introduces the concepts of regression in a very introductory way. To expand on this, it is recommended to explore further based on your interests and needs.\n",
    "\n",
    "In the field of *machine learning*, the main areas for deeper exploration are:\n",
    "\n",
    "-   Alternative regression models like random forests.\n",
    "-   *Boosting* and *bagging* methods to learn how multiple models can be trained jointly and their predictions combined democratically to converge on better decisions than a single model.\n",
    "-   Issues related to model explainability, a very active research area, to better understand the decision criteria of models.\n",
    "\n",
    "In the field of econometrics, the main areas for deeper exploration are:\n",
    "\n",
    "-   Generalized linear models to explore regression with more general assumptions than those we have made so far;\n",
    "-   Hypothesis testing to delve deeper into these questions beyond our likelihood ratio test.\n",
    "\n",
    "## References\n",
    "\n",
    "Siegfried, André. 1913. *Tableau Politique de La France de l’ouest Sous La Troisième république: 102 Cartes Et Croquis, 1 Carte Hors Texte*. A. Colin."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3",
   "path": "/home/runner/work/python-datascientist/python-datascientist/.venv/share/jupyter/kernels/python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": "3"
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
